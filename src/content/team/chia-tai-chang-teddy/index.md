---
title: "Chia-Tai Chang"
description: "B.S. Student @ NTU CSIE | AI Security Lab"
summary: "Research focuses on mechanistic interpretability (sparse autoencoders for multi-preference alignment) and machine unlearning via adversarial perturbation."
date: 2026-01-31
role: "organizer"
weight: 2
draft: false
image: "avatar.jpg"
social:
  - email: "mailto:jiataizang@gmail.com"
  - linkedin: "https://www.linkedin.com/in/chia-tai-chang-339886212/"
---

I am a junior in Computer Science and Information Engineering at National Taiwan University. At the NTU AI Security Lab, my research focuses on two areas:

1. **Mechanistic Interpretability**: Developing sparse autoencoder–based reward models to fine-tune LLMs for multi-preference alignment (e.g., balancing helpfulness and harmlessness).
2. **Machine Unlearning**: Adversarial perturbation methods, including work on CLIP model tuning.

I joined the lab through the NTU AI Safety reading group, drawn by my interest in mechanistic interpretability and sparse autoencoder research—a path similar to my colleague Leo's.

**Expected graduation date:** 2027

## Contact

- [Email](mailto:jiataizang@gmail.com)
- [LinkedIn](https://www.linkedin.com/in/chia-tai-chang-339886212/)
